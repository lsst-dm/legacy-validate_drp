__all__ = ["MatchedVisitMetricsRunner", "MatchedVisitMetricsConfig", "MatchedVisitMetricsTask"]

import os

from lsst.pipe.base import CmdLineTask, ArgumentParser, TaskRunner
from lsst.pex.config import Config, Field
from lsst.meas.base.forcedPhotCcd import PerTractCcdDataIdContainer
from .validate import runOneFilter, plot_metrics


class MatchedVisitMetricsRunner(TaskRunner):
    """Subclass of TaskRunner for MatchedVisitMetrics

    This class transforms the processed
    arguments generated by the ArgumentParser into the arguments expected by
    MatchedVisitMetricsTask.run().
    """

    @classmethod
    def getTargetList(cls, parsedCmd, **kwargs):
        # organize data IDs by filter
        id_list_dict = {}
        for ref in parsedCmd.id.refList:
            id_list_dict.setdefault(ref.dataId["filter"], []).append(ref.dataId)
        # we call run() once with each filter
        return [(parsedCmd.butler,
                 filterName,
                 parsedCmd.output,
                 id_list_dict[filterName],
                 ) for filterName in sorted(id_list_dict.keys())]

    def __call__(self, args):
        task = self.TaskClass(config=self.config, log=self.log)
        return task.run(*args)


class MatchedVisitMetricsConfig(Config):
    instrumentName = Field(
        dtype=str, optional=False,
        doc="Instrument name to associate with verification specifications: e.g. HSC, CFHT, DECAM"
    )
    datasetName = Field(
        dtype=str, optional=False,
        doc="Dataset name to associate metric measuremnts in SQuaSH"
    )
    outputPrefix = Field(
        dtype=str, default="matchedVisit",
        doc="Root name for output files: the filter name is appended to this+'_'."
    )
    metricsRepository = Field(
        dtype=str, default='verify_metrics',
        doc="Repository to read metrics and specs from."
    )
    brightSnr = Field(
        dtype=float, default=100,
        doc="Minimum PSF signal-to-noise ratio for a star to be considered bright."
    )
    safeSnr = Field(
        dtype=float, default=50,
        doc="Minimum median PSF signal-to-noise ratio for a match to be considered safe."
    )
    makeJson = Field(
        dtype=bool, default=True,
        doc="Whether to write JSON outputs."
    )
    makePlots = Field(
        dtype=bool, default=True,
        doc="Whether to write plot outputs."
    )
    matchRadius = Field(
        dtype=float, default=1.0,
        doc="Match radius (arcseconds)."
    )
    useJointCal = Field(
        dtype=bool, default=False,
        doc="Whether to use jointcal (or meas_mosaic) to calibrate measurements"
    )
    skipTEx = Field(
        dtype=bool, default=False,
        doc="Skip TEx calculations (useful for older catalogs that don't have PsfShape measurements)."
    )
    verbose = Field(
        dtype=bool, default=False,
        doc="More verbose output during validate calculations."
    )


class MatchedVisitMetricsTask(CmdLineTask):
    """An alternate command-line driver for the validate_drp metrics.

    MatchedVisitMetricsTask is very much an incomplete CmdLineTask - it uses
    the usual mechanisms to define its inputs and read them using a Butler,
    but writes outputs manually to files with a configuration-defined prefix
    (config.outputPrefix).  Because the CmdLineTask machinery always creates an
    output Butler repository, however, it is necessary to run this task with
    both an output directory and an output prefix, with the former essentially
    unused.

    The input data IDs passed via the `--id` argument should contain the same
    keys as the `wcs` dataset (those used by the `calexp` dataset plus
    `tract`).  When `config.useJointCal` is `True`, the `photoCalib` and `wcs`
    datasets are used to calibrate sources; when it is `False`, `tract` is
    ignored (but must still be present) and the photometric calibration is
    retrieved from the `calexp` and the sky positions of sources are loaded
    directly from the `src` dataset (which is used to obtain raw measurmenets
    in both cases).
    """

    _DefaultName = "matchedVisitMetrics"
    ConfigClass = MatchedVisitMetricsConfig
    RunnerClass = MatchedVisitMetricsRunner

    def run(self, butler, filterName, output, dataIds):
        """
        Compute cross-visit metrics for one filter.

        Parameters
        ----------
        butler      The initialized butler.
        filterName  The filter name to be processed.
        output      The output repository to save files to.
        dataIds     The butler dataIds to process.
        """
        output_prefix = os.path.join(output, "%s_%s"%(self.config.outputPrefix, filterName))
        # Metrics are no longer passed. The argument will go away with DM-14274
        job = runOneFilter(butler, dataIds, metrics=None,
                           brightSnr=self.config.brightSnr,
                           makeJson=self.config.makeJson,
                           filterName=filterName,
                           outputPrefix=output_prefix,
                           useJointCal=self.config.useJointCal,
                           skipTEx=self.config.skipTEx,
                           verbose=self.config.verbose,
                           metrics_package=self.config.metricsRepository,
                           instrument=self.config.instrumentName,
                           dataset_repo_url=self.config.datasetName)
        if self.config.makePlots:
            plot_metrics(job, filterName, outputPrefix=output_prefix)

    @classmethod
    def _makeArgumentParser(cls):
        parser = ArgumentParser(name=cls._DefaultName)
        parser.add_id_argument("--id", "jointcal_wcs", help="data ID, with raw CCD keys + tract",
                               ContainerClass=PerTractCcdDataIdContainer)
        return parser

    def _getConfigName(self):
        return None

    def _getMetadataName(self):
        return None
